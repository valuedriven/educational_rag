{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Educational RAG\n",
    "\n",
    "### A question answering agent based on some UNESCO publications\n",
    "\n",
    "This project use RAG (Retrieval Augmented Generation) to ensure the assistant accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"gpt-4o-mini\"\n",
    "db_name = \"../data/educational_db\"\n",
    "knowledge_base = \"../data/knowledge-base/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'key-if-not-using-dotenv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 123\n",
      "Document types found: {'contracts', 'products', 'employees', 'company'}\n"
     ]
    }
   ],
   "source": [
    "folders = glob.glob(knowledge_base)\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78998399-ac17-4e28-b15f-0b5f51e6ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 123 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2e7687-60d4-4920-a1d7-a34b9f70a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e4f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='8ac98bc4-413a-4935-878d-468f9b52a84d', metadata={'doc_type': 'company', 'source': '../data/knowledge-base/company/about.md'}, page_content=\"# About Insurellm\\n\\nInsurellm was founded by Avery Lancaster in 2015 as an insurance tech startup designed to disrupt an industry in need of innovative products. It's first product was Markellm, the marketplace connecting consumers with insurance providers.\\nIt rapidly expanded, adding new products and clients, reaching 200 emmployees by 2024 with 12 offices across the US.\"), Document(id='a4a86c7a-38ce-48b1-9f66-57d62032765c', metadata={'source': '../data/knowledge-base/company/overview.md', 'doc_type': 'company'}, page_content='# Overview of Insurellm\\n\\nInsurellm is an innovative insurance tech firm with 200 employees across the US.\\nInsurellm offers 4 insurance software products:\\n- Carllm, a portal for auto insurance companies\\n- Homellm, a portal for home insurance companies\\n- Rellm, an enterprise platform for the reinsurance sector\\n- Marketllm, a marketplace for connecting consumers with insurance providers\\n  \\nInsurellm has more than 300 clients worldwide.'), Document(id='0de7db40-6799-41e9-bdc1-c023033146a6', metadata={'doc_type': 'products', 'source': '../data/knowledge-base/products/Homellm.md'}, page_content='With Homellm, Insurellm is committed to transforming the landscape of home insurance, ensuring both innovation and reliability for all insurance providers and their customers. Explore the future of home insurance today with Homellm!'), Document(id='dd13191e-94d8-40d2-8272-c0de926497c1', metadata={'doc_type': 'products', 'source': '../data/knowledge-base/products/Rellm.md'}, page_content='Experience the future of reinsurance with Rellm, where innovation meets reliability. Let Insurellm help you navigate the complexities of the reinsurance market smarter and faster.')]\n"
     ]
    }
   ],
   "source": [
    "query = \"Please explain what Insurellm is in a couple of sentences\"\n",
    "retrieved_docs = vectorstore.similarity_search(query)\n",
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d45462-a818-441c-b010-b85b32bcf618",
   "metadata": {},
   "source": [
    "## Visualizing the Vector Store\n",
    "\n",
    "Let's take a minute to look at the documents and their embedding vectors to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98adf5e-d464-4bd2-9bdf-bc5b6770263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e598e7",
   "metadata": {},
   "source": [
    "We humans find it easier to visalize things in 2D!\n",
    "Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "(t-distributed stochastic neighbor embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427149d5-e5d8-4abd-bb6f-7ef0333cca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1418e88-acd5-460a-bf2b-4e6efc88e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468860b-86a2-41df-af01-b2400cc985be",
   "metadata": {},
   "source": [
    "## Setup LangChain chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6631829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "model = init_chat_model(selected_model, temperature=0.7)\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vectorstore.similarity_search(query,k=2)    \n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"metadata: {doc.metadata}\\npage_content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "tools = [retrieve_context]\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "   You are an expert in answering accurate questions about Insurellm, the Insurance Tech company.\n",
    "   Give brief, accurate answers. If you don't know the answer, say so.\n",
    "   Do not make anything up if you haven't been provided with relevant context.\n",
    " \"\"\" \n",
    "\n",
    "memory = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=memory,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "968e7bf2-e862-4679-a11f-6c1efb6ec8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Insurellm is an insurance tech startup founded by Avery Lancaster in 2015, aimed at disrupting the insurance industry with innovative products. Its first product, Markellm, connects consumers with insurance providers. By 2024, the company had expanded to 200 employees and 12 offices across the U.S. Additionally, Insurellm offers Homellm, which focuses on transforming home insurance with innovation and reliability.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "query = \"Please explain what Insurellm is in a couple of sentences\"\n",
    "result = result = agent.invoke({\"question\": query}, config)\n",
    "result[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316743ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (283846273.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"messages\": [{\"role\": \"user\", \"content\": message}], config\u001b[39m\n                                                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "# def chat(question, history):\n",
    "#     result = agent.invoke({\"question\": question}, config)\n",
    "#     return result[\"messages\"][-1].pretty_print()\n",
    "def chat(message, history):\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": message}]\n",
    "    },config)\n",
    "    return result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcb659-13ce-47ab-8a5e-01b930494964",
   "metadata": {},
   "source": [
    "## Setup Gradio using the Chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b252d8c1-61a8-406d-b57a-8f708a62b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/chat_interface.py\", line 553, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/gradio/chat_interface.py\", line 943, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_21908/204926062.py\", line 5, in chat\n",
      "    result = agent.invoke({\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py\", line 3094, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py\", line 2551, in stream\n",
      "    ) = self._defaults(\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/s676922906/projetos/educational_rag/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py\", line 2421, in _defaults\n",
      "    raise ValueError(\n",
      "ValueError: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id\n"
     ]
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
